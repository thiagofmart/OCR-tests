{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ctrl+shift+p -> Notebook: Select Notebook Kernel -> venv\n",
    "from pdf2image import convert_from_path\n",
    "from pytesseract import pytesseract\n",
    "from PIL import Image, ImageFilter\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_pdf_to_img(pdf_file):\n",
    "    return convert_from_path(\n",
    "        pdf_path=pdf_file, \n",
    "        dpi=500, \n",
    "        #output_folder=\"./output\", \n",
    "        poppler_path=r\"C:\\Program Files\\poppler-23.01.0\\Library\\bin\",\n",
    "        )\n",
    "\n",
    "\n",
    "def convert_image_to_text(image):\n",
    "    pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "    os.environ['TESSDATA_PREFIX'] = r'C:\\Program Files\\Tesseract-OCR\\tessdata'\n",
    "    return pytesseract.image_to_string(image, lang=\"por\")\n",
    "\n",
    "\n",
    "def save(img, name):\n",
    "    cv2.imwrite(name, img)\n",
    "\n",
    "\n",
    "def get_concat_v(im1, im2): # vertical image concatenation using PIL lib\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "\n",
    "def show(img_array):\n",
    "    im = Image.fromarray(img_array)\n",
    "    im.show()\n",
    "\n",
    "\n",
    "def process_image(image, ksize, threshold = np.array([0])):\n",
    "    if not np.any(threshold):\n",
    "        # Apply grayscale to the image\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        # Apply blur\n",
    "        blur = cv2.GaussianBlur(gray, (7, 7), 0)\n",
    "        # Apply thresholding to the grayscale image\n",
    "        _, threshold = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    # Dilation \n",
    "    kernel = cv2.getStructuringElement(\n",
    "        shape=cv2.MORPH_RECT, \n",
    "        ksize=ksize,\n",
    "        ) # manual adjust of x, y dilation\n",
    "    dilate = cv2.dilate(threshold, kernel, iterations=1)\n",
    "    # Finding the Countours from the dilated image\n",
    "    contours = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours)==2 else contours[1]\n",
    "    contours = sorted(contours, key=lambda x: cv2.boundingRect(x)[1])\n",
    "    return contours, image, threshold \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the pdf and converting all the pages into one single image file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file = \"REALFLEX.pdf\"\n",
    "images = convert_pdf_to_img(pdf_file)\n",
    "w, h = images[0].size\n",
    "images = [image.crop((0, 100, w, h-100)) for image in images]\n",
    "im_v = get_concat_v(images[0].crop((0, 330, w, h-200)), images[1])\n",
    "for pg, image in enumerate(images[2:]):\n",
    "    im_v = get_concat_v(im_v, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process IMAGE and get The contours\n",
    "contours, image, threshold = process_image(np.array(im_v), ksize=(1400, 80))\n",
    "\n",
    "# Extracting each part\n",
    "cropped_images = []\n",
    "for c in contours:\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "    if h > 200 and w > 800:\n",
    "        cropped_images.append({\n",
    "            \"original\": image[y:y+h, x:x+w],\n",
    "            \"threshold\": threshold[y:y+h, x:x+w],\n",
    "            })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spliting all sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cropped_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m data_structures_list \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mkeys()\n\u001b[0;32m     11\u001b[0m current_data_struct \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInformações Gerais da Inscrição\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfor\u001b[39;00m cropped_image \u001b[39min\u001b[39;00m [cropped_images[\u001b[39m4\u001b[39m],]: \n\u001b[0;32m     13\u001b[0m     cnts, cropped_image, _thrs \u001b[39m=\u001b[39m process_image(\n\u001b[0;32m     14\u001b[0m         image\u001b[39m=\u001b[39mcropped_image[\u001b[39m\"\u001b[39m\u001b[39moriginal\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m     15\u001b[0m         threshold\u001b[39m=\u001b[39mcropped_image[\u001b[39m\"\u001b[39m\u001b[39mthreshold\u001b[39m\u001b[39m\"\u001b[39m], \n\u001b[0;32m     16\u001b[0m         ksize\u001b[39m=\u001b[39m(\u001b[39m30\u001b[39m, \u001b[39m17\u001b[39m))\n\u001b[0;32m     17\u001b[0m     sentences \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cropped_images' is not defined"
     ]
    }
   ],
   "source": [
    "data_structures = {\n",
    "    \"Informações Gerais da Inscrição\":[],\n",
    "    \"Informações Sobre os Valores da Inscrição\":[],\n",
    "    \"Informações dos Devedores\":[],\n",
    "    \"Informações Sobre os Débitos da Inscrição\":[],\n",
    "    \"Informações Sobre o parcelamento\":[],\n",
    "    \"Informações sobre os pagamentos\":[],\n",
    "    \"Informações de ocorrências\":[],\n",
    "}\n",
    "data_structures_list = data_structures.keys()\n",
    "current_data_struct = \"Informações Gerais da Inscrição\"\n",
    "for cropped_image in [cropped_images[4],]: \n",
    "    cnts, cropped_image, _thrs = process_image(\n",
    "        image=cropped_image[\"original\"], \n",
    "        threshold=cropped_image[\"threshold\"], \n",
    "        ksize=(30, 17))\n",
    "    sentences = []\n",
    "    texts = []\n",
    "    for c in cnts:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if h < 150 and w > 10 and h > 50:\n",
    "            sentence = cropped_image[y:y+h, x:x+w]\n",
    "            text = convert_image_to_text(sentence).strip().replace(\"\\n\", \"\")\n",
    "            if len(text)!=0:\n",
    "                if text in data_structures_list:\n",
    "                    current_data_struct = text\n",
    "                sentences.append(sentence)\n",
    "                texts.append(text)\n",
    "            #cv2.rectangle(cropped_image, (x,y), (x+w, y+h), (12, 255, 36), 2)\n",
    "    data_structures[current_data_struct].append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structures[\"Informações Sobre os Débitos da Inscrição\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_consulta_inscricao(pdf_file):\n",
    "    images = convert_pdf_to_img(pdf_file)\n",
    "    w, h = images[0].size\n",
    "    images = [image.crop((0, 100, w, h-100)) for image in images]\n",
    "    im_v = get_concat_v(images[0].crop((0, 330, w, h-200)), images[1])\n",
    "    for pg, image in enumerate(images[2:]):\n",
    "        im_v = get_concat_v(im_v, image)\n",
    "    #\n",
    "    data_structures = {\n",
    "        \"Informações Gerais da Inscrição\":[],\n",
    "        \"Informações Sobre os Valores da Inscrição\":[],\n",
    "        \"Informações dos Devedores\":[],\n",
    "        \"Informações Sobre os Débitos da Inscrição\":[],\n",
    "        \"Informações sobre o parcelamento\":[],\n",
    "        \"Informações sobre os pagamentos efetuados\":[],\n",
    "        \"Informações de ocorrências\":[],\n",
    "    }\n",
    "    data_structures_list = data_structures.keys()\n",
    "    current_data_struct = \"Informações Gerais da Inscrição\"\n",
    "    # Process IMAGE and get The contours\n",
    "    contours, image, threshold = process_image(np.array(im_v), ksize=(1400, 80))\n",
    "    # Extracting each part\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        if h > 200 and w > 800:\n",
    "            cnts, cropped_image, _thrs = process_image(\n",
    "                    image=image[y:y+h, x:x+w], \n",
    "                    threshold=threshold[y:y+h, x:x+w], \n",
    "                    ksize=(30, 17),\n",
    "                )\n",
    "            texts = []\n",
    "            for _c in cnts:\n",
    "                x, y, w, h = cv2.boundingRect(_c)\n",
    "                if h < 150 and w > 10 and h > 50:\n",
    "                    sentence = cropped_image[y:y+h, x:x+w]\n",
    "                    thresholded_sentence = _thrs[y:y+h, x:x+w]\n",
    "                    text = convert_image_to_text(thresholded_sentence).strip().replace(\"\\n\", \"\")\n",
    "                    if len(text)!=0:\n",
    "                        if text in data_structures_list:\n",
    "                            current_data_struct = text\n",
    "                        texts.append(text)\n",
    "            data_structures[current_data_struct].append(texts)\n",
    "    return data_structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pdf_file = \"REALFLEX.pdf\"\n",
    "data_structures = get_text_consulta_inscricao(pdf_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_structures.keys()\n",
    "writer = pd.ExcelWriter(\"demo.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "with open(\"demo.json\", \"w\", encoding=\"utf-8\") as file:\n",
    "    json.dump(data_structures, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_structures[\"Informações Gerais da Inscrição\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc7cc3e37fbb68bbf0580a1b81c914a8e620970691a3cfd944411967dcf03708"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
